{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8zvPA9fIty5c",
        "outputId": "7fdae26c-5a37-4d70-9922-cfc358d7a769"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'nanoGPT'...\n",
            "remote: Enumerating objects: 686, done.\u001b[K\n",
            "remote: Counting objects: 100% (2/2), done.\u001b[K\n",
            "remote: Compressing objects: 100% (2/2), done.\u001b[K\n",
            "remote: Total 686 (delta 0), reused 0 (delta 0), pack-reused 684 (from 2)\u001b[K\n",
            "Receiving objects: 100% (686/686), 959.50 KiB | 29.98 MiB/s, done.\n",
            "Resolving deltas: 100% (385/385), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/alexkalitenko125/nanoGPT"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install tiktoken transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8cs9c2P1fvRn",
        "outputId": "a1b08253-40cf-4798-ae60-29e223a07a44"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tiktoken\n",
            "  Downloading tiktoken-0.8.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.47.1)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2024.11.6)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2.32.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.16.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.27.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.21.0)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (2024.10.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (2024.12.14)\n",
            "Downloading tiktoken-0.8.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m38.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: tiktoken\n",
            "Successfully installed tiktoken-0.8.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cd ./nanoGPT/data/shakespeare/ && python prepare.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XxoMQ8IMt8Bu",
        "outputId": "1f5cacde-48fd-4056-c61e-808677972448"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train has 301,966 tokens\n",
            "val has 36,059 tokens\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cd ./nanoGPT/ && python train.py --dtype=float16 --dataset=shakespeare --compile=False --n_layer=4 --n_head=4 --n_embd=64 --block_size=64 --batch_size=8 --init_from=gpt2 --eval_interval=100 --eval_iters=100 --max_iters=100 --bias=True"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MBXoH_7tunr6",
        "outputId": "a783507b-21bb-42ac-b04a-03d4d4718f33"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overriding: dtype = float16\n",
            "Overriding: dataset = shakespeare\n",
            "Overriding: compile = False\n",
            "Overriding: n_layer = 4\n",
            "Overriding: n_head = 4\n",
            "Overriding: n_embd = 64\n",
            "Overriding: block_size = 64\n",
            "Overriding: batch_size = 8\n",
            "Overriding: init_from = gpt2\n",
            "Overriding: eval_interval = 100\n",
            "Overriding: eval_iters = 100\n",
            "Overriding: max_iters = 100\n",
            "Overriding: bias = True\n",
            "tokens per iteration will be: 20,480\n",
            "Initializing from OpenAI GPT-2 weights: gpt2\n",
            "2025-01-05 12:53:50.486589: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2025-01-05 12:53:50.505762: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2025-01-05 12:53:50.511617: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2025-01-05 12:53:50.526227: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2025-01-05 12:53:51.718797: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "loading weights from pretrained gpt: gpt2\n",
            "forcing vocab_size=50257, block_size=1024, bias=True\n",
            "overriding dropout rate to 0.0\n",
            "number of parameters: 123.65M\n",
            "config.json: 100% 665/665 [00:00<00:00, 4.26MB/s]\n",
            "model.safetensors: 100% 548M/548M [00:02<00:00, 210MB/s]\n",
            "generation_config.json: 100% 124/124 [00:00<00:00, 599kB/s]\n",
            "/content/nanoGPT/train.py:196: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = torch.cuda.amp.GradScaler(enabled=(dtype == 'float16'))\n",
            "num decayed parameter tensors: 50, with 123,581,184 parameters\n",
            "num non-decayed parameter tensors: 98, with 121,344 parameters\n",
            "using fused AdamW: True\n",
            "step 0: train loss 4.9566, val loss 4.8729\n",
            "iter 0: loss 5.3318, time 5823.86ms, mfu -100.00%\n",
            "iter 1: loss 5.0240, time 1660.76ms, mfu -100.00%\n",
            "iter 2: loss 4.9148, time 1753.59ms, mfu -100.00%\n",
            "iter 3: loss 4.9427, time 1767.11ms, mfu -100.00%\n",
            "iter 4: loss 4.8243, time 1760.75ms, mfu -100.00%\n",
            "iter 5: loss 5.1061, time 1756.93ms, mfu 2.80%\n",
            "iter 6: loss 4.9370, time 1760.60ms, mfu 2.80%\n",
            "iter 7: loss 5.1047, time 1763.39ms, mfu 2.80%\n",
            "iter 8: loss 4.7785, time 1761.69ms, mfu 2.80%\n",
            "iter 9: loss 4.9612, time 1765.69ms, mfu 2.80%\n",
            "iter 10: loss 4.7506, time 1769.72ms, mfu 2.79%\n",
            "iter 11: loss 4.6786, time 1773.51ms, mfu 2.79%\n",
            "iter 12: loss 4.9943, time 1774.25ms, mfu 2.79%\n",
            "iter 13: loss 4.8238, time 1771.98ms, mfu 2.79%\n",
            "iter 14: loss 4.5512, time 1775.03ms, mfu 2.79%\n",
            "iter 15: loss 4.6082, time 1778.21ms, mfu 2.78%\n",
            "iter 16: loss 4.2203, time 1778.93ms, mfu 2.78%\n",
            "iter 17: loss 4.3476, time 1789.75ms, mfu 2.78%\n",
            "iter 18: loss 4.3461, time 1787.03ms, mfu 2.78%\n",
            "iter 19: loss 4.5730, time 1787.94ms, mfu 2.77%\n",
            "iter 20: loss 4.3588, time 1786.80ms, mfu 2.77%\n",
            "iter 21: loss 4.4304, time 1792.21ms, mfu 2.77%\n",
            "iter 22: loss 4.2282, time 1795.15ms, mfu 2.77%\n",
            "iter 23: loss 4.3336, time 1796.14ms, mfu 2.76%\n",
            "iter 24: loss 4.2547, time 1800.05ms, mfu 2.76%\n",
            "iter 25: loss 4.0933, time 1804.95ms, mfu 2.76%\n",
            "iter 26: loss 4.2057, time 1801.64ms, mfu 2.75%\n",
            "iter 27: loss 4.2162, time 1811.11ms, mfu 2.75%\n",
            "iter 28: loss 4.0896, time 1809.75ms, mfu 2.75%\n",
            "iter 29: loss 4.1052, time 1808.41ms, mfu 2.74%\n",
            "iter 30: loss 3.8646, time 1816.19ms, mfu 2.74%\n",
            "iter 31: loss 4.1885, time 1815.75ms, mfu 2.74%\n",
            "iter 32: loss 4.3206, time 1823.81ms, mfu 2.73%\n",
            "iter 33: loss 4.1549, time 1829.70ms, mfu 2.73%\n",
            "iter 34: loss 3.9027, time 1832.74ms, mfu 2.72%\n",
            "iter 35: loss 4.1550, time 1828.45ms, mfu 2.72%\n",
            "iter 36: loss 4.1159, time 1834.01ms, mfu 2.72%\n",
            "iter 37: loss 4.1171, time 1839.06ms, mfu 2.71%\n",
            "iter 38: loss 3.7594, time 1836.33ms, mfu 2.71%\n",
            "iter 39: loss 4.2037, time 1846.00ms, mfu 2.70%\n",
            "iter 40: loss 3.7349, time 1850.10ms, mfu 2.70%\n",
            "iter 41: loss 3.9777, time 1845.42ms, mfu 2.70%\n",
            "iter 42: loss 4.2228, time 1848.70ms, mfu 2.69%\n",
            "iter 43: loss 3.8032, time 1856.22ms, mfu 2.69%\n",
            "iter 44: loss 3.7838, time 1852.47ms, mfu 2.68%\n",
            "iter 45: loss 3.7765, time 1853.38ms, mfu 2.68%\n",
            "iter 46: loss 3.8239, time 1858.17ms, mfu 2.68%\n",
            "iter 47: loss 4.0554, time 1853.56ms, mfu 2.68%\n",
            "iter 48: loss 3.8072, time 1849.33ms, mfu 2.67%\n",
            "iter 49: loss 3.9230, time 1849.21ms, mfu 2.67%\n",
            "iter 50: loss 4.0619, time 1841.18ms, mfu 2.67%\n",
            "iter 51: loss 4.0551, time 1835.64ms, mfu 2.67%\n",
            "iter 52: loss 3.9684, time 1839.42ms, mfu 2.67%\n",
            "iter 53: loss 3.6327, time 1838.33ms, mfu 2.67%\n",
            "iter 54: loss 3.8589, time 1839.29ms, mfu 2.67%\n",
            "iter 55: loss 3.4326, time 1830.55ms, mfu 2.67%\n",
            "iter 56: loss 3.6846, time 1830.39ms, mfu 2.68%\n",
            "iter 57: loss 3.6484, time 1830.82ms, mfu 2.68%\n",
            "iter 58: loss 4.1991, time 1823.49ms, mfu 2.68%\n",
            "iter 59: loss 3.6483, time 1828.83ms, mfu 2.68%\n",
            "iter 60: loss 3.9266, time 1836.90ms, mfu 2.68%\n",
            "iter 61: loss 3.6199, time 1818.47ms, mfu 2.68%\n",
            "iter 62: loss 4.1771, time 1824.06ms, mfu 2.68%\n",
            "iter 63: loss 3.7491, time 1822.74ms, mfu 2.68%\n",
            "iter 64: loss 3.8521, time 1823.12ms, mfu 2.69%\n",
            "iter 65: loss 3.3935, time 1823.60ms, mfu 2.69%\n",
            "iter 66: loss 3.9659, time 1818.92ms, mfu 2.69%\n",
            "iter 67: loss 3.5933, time 1820.09ms, mfu 2.69%\n",
            "iter 68: loss 3.6902, time 1826.46ms, mfu 2.69%\n",
            "iter 69: loss 3.9797, time 1820.04ms, mfu 2.69%\n",
            "iter 70: loss 3.4157, time 1820.11ms, mfu 2.69%\n",
            "iter 71: loss 3.7341, time 1820.97ms, mfu 2.69%\n",
            "iter 72: loss 3.7133, time 1824.57ms, mfu 2.69%\n",
            "iter 73: loss 3.6217, time 1822.10ms, mfu 2.69%\n",
            "iter 74: loss 3.7237, time 1825.67ms, mfu 2.69%\n",
            "iter 75: loss 3.3708, time 1829.25ms, mfu 2.69%\n",
            "iter 76: loss 3.9233, time 1826.16ms, mfu 2.69%\n",
            "iter 77: loss 4.0395, time 1827.56ms, mfu 2.69%\n",
            "iter 78: loss 3.0585, time 1827.49ms, mfu 2.69%\n",
            "iter 79: loss 3.5398, time 1824.18ms, mfu 2.69%\n",
            "iter 80: loss 3.3604, time 1826.45ms, mfu 2.69%\n",
            "iter 81: loss 3.8117, time 1826.22ms, mfu 2.69%\n",
            "iter 82: loss 3.4533, time 1831.73ms, mfu 2.69%\n",
            "iter 83: loss 3.6080, time 1833.49ms, mfu 2.69%\n",
            "iter 84: loss 3.7084, time 1831.12ms, mfu 2.69%\n",
            "iter 85: loss 4.2363, time 1828.06ms, mfu 2.69%\n",
            "iter 86: loss 3.4696, time 1831.72ms, mfu 2.69%\n",
            "iter 87: loss 3.6149, time 1826.47ms, mfu 2.69%\n",
            "iter 88: loss 3.3281, time 1831.33ms, mfu 2.69%\n",
            "iter 89: loss 3.9213, time 1831.48ms, mfu 2.69%\n",
            "iter 90: loss 3.4582, time 2205.32ms, mfu 2.64%\n",
            "iter 91: loss 3.6763, time 1831.85ms, mfu 2.65%\n",
            "iter 92: loss 3.3227, time 1834.17ms, mfu 2.65%\n",
            "iter 93: loss 3.5250, time 1830.07ms, mfu 2.65%\n",
            "iter 94: loss 3.5029, time 1832.61ms, mfu 2.66%\n",
            "iter 95: loss 3.5739, time 1830.61ms, mfu 2.66%\n",
            "iter 96: loss 3.5543, time 1833.66ms, mfu 2.66%\n",
            "iter 97: loss 3.3529, time 1835.08ms, mfu 2.66%\n",
            "iter 98: loss 3.4811, time 1829.64ms, mfu 2.67%\n",
            "iter 99: loss 3.5569, time 1828.94ms, mfu 2.67%\n",
            "step 100: train loss 3.5381, val loss 3.6054\n",
            "saving checkpoint to out\n",
            "iter 100: loss 3.5721, time 13549.88ms, mfu 2.44%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cd ./nanoGPT && python sample.py --dtype=float16 --num_samples=1 --max_new_tokens=100 --start=\"to be or\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GOjpslgu6g4Y",
        "outputId": "06a7e16f-5e31-4533-9198-8f2a1a8169b4"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overriding: dtype = float16\n",
            "Overriding: num_samples = 1\n",
            "Overriding: max_new_tokens = 100\n",
            "Overriding: start = to be or\n",
            "/content/nanoGPT/sample.py:38: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  checkpoint = torch.load(ckpt_path, map_location=device)\n",
            "number of parameters: 123.65M\n",
            "No meta.pkl found, assuming GPT-2 encodings...\n",
            "to be or perish.\n",
            "\n",
            "DUKE OF YORK:\n",
            "I cannot do it for no other reason than,\n",
            "For my own sake, that I should be more\n",
            "Orselious than they.\n",
            "I have the mind for Rome, but I have no more\n",
            "Than myself: but I have the mind for Paris!\n",
            "\n",
            "DUKE OF YORK:\n",
            "Madam; but I am well told that John\n",
            "Amirdine, the present king, is a master\n",
            "Of the\n",
            "---------------\n"
          ]
        }
      ]
    }
  ]
}